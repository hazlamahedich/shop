# Backend Environment Configuration
# Copy this file to .env and fill in your values

# Testing Mode (forces mock services, prevents API costs)
IS_TESTING=false

# Application Settings
APP_NAME=shop-backend
APP_VERSION=0.1.0
DEBUG=true

# Security (REQUIRED in production - generate with: python -c "import secrets; print(secrets.token_urlsafe(32))")
SECRET_KEY=change-this-to-a-random-secret-key-in-production

# Database (PostgreSQL)
# Note: For testing, create database first: createdb shop_dev -U developer
DATABASE_URL=postgresql+asyncpg://developer:developer@localhost:5432/shop_dev
DATABASE_ECHO=false

# Test Database (optional - defaults to DATABASE_URL if not set)
TEST_DATABASE_URL=postgresql+asyncpg://developer:developer@localhost:5432/shop_dev

# Redis
REDIS_URL=redis://localhost:6379/0

# Security
WEBHOOK_SECRET=webhook-secret-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Shopify (configure during onboarding)
SHOPIFY_API_KEY=
SHOPIFY_API_SECRET=
SHOPIFY_ENCRYPTION_KEY=  # Generate with: python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
SHOPIFY_REDIRECT_URI=https://your-domain.com/api/integrations/shopify/callback
SHOPIFY_WEBHOOK_URL=https://your-domain.com/api/webhooks/shopify
SHOPIFY_STORE_URL=
SHOPIFY_STOREFRONT_TOKEN=
SHOPIFY_API_VERSION=2024-01

# Facebook Messenger (configure during onboarding)
FACEBOOK_APP_ID=
FACEBOOK_APP_SECRET=
FACEBOOK_API_VERSION=v19.0
FACEBOOK_REDIRECT_URI=https://your-domain.com/api/integrations/facebook/callback
FACEBOOK_ENCRYPTION_KEY=  # Generate with: python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'
FACEBOOK_WEBHOOK_VERIFY_TOKEN=  # Generate with: python -c 'import secrets; print(secrets.token_urlsafe(32))'
# Legacy aliases (kept for compatibility)
FACEBOOK_PAGE_ID=
FACEBOOK_PAGE_ACCESS_TOKEN=
FACEBOOK_VERIFY_TOKEN=verify_token

# LLM Provider (configure during onboarding)
LLM_PROVIDER=ollama  # Options: ollama, openai, anthropic, gemini, glm
LLM_API_KEY=
LLM_API_BASE=
LLM_MODEL=
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000

# Ollama Configuration (local, free)
OLLAMA_DEFAULT_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3  # Options: llama3, mistral, qwen2, codellama

# OpenAI Configuration (optional backup)
OPENAI_API_KEY=
OPENAI_DEFAULT_MODEL=gpt-4o-mini  # Options: gpt-4o-mini, gpt-4o, gpt-3.5-turbo

# Anthropic Configuration (optional backup)
ANTHROPIC_API_KEY=
ANTHROPIC_DEFAULT_MODEL=claude-3-haiku  # Options: claude-3-haiku, claude-3-sonnet

# Google Gemini Configuration (optional backup)
GEMINI_API_KEY=
GEMINI_DEFAULT_MODEL=gemini-1.5-flash  # Options: gemini-1.5-flash, gemini-pro

# GLM-4.7 Configuration (China market, optional backup)
GLM_API_KEY=
GLM_DEFAULT_MODEL=glm-4-flash  # Options: glm-4-flash, glm-4-plus

# CORS (comma-separated list of allowed origins)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173
